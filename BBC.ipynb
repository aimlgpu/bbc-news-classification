{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "ad4914cf-5982-47e5-95b9-7723d1ddac04",
      "cell_type": "code",
      "source": "# BBC News Classification Kaggle Mini-Project\n## 1. Exploratory Data Analysis\n# Analyze the dataset to understand category distribution, text length, and common words.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport os\n\n# Add local nltk_data to NLTK path\nnltk.data.path.append(os.path.join(os.getcwd(), 'nltk_data'))\n\n# Function to find datasets\ndef find_dataset(filename):\n    possible_paths = [\n        os.path.join('data', filename),  # data subfolder (primary)\n        filename,  # Current directory\n        os.path.join('datasets', filename)  # datasets subfolder\n    ]\n    for path in possible_paths:\n        if os.path.exists(path):\n            return path\n    raise FileNotFoundError(f\"Dataset '{filename}' not found in {os.getcwd()}. Checked paths: {possible_paths}. Please place the file in the 'data' folder.\")\n\n# Load the dataset\ntry:\n    dataset_path = find_dataset('BBC News Train.csv')\n    train_df = pd.read_csv(dataset_path)\nexcept FileNotFoundError as e:\n    print(e)\n    print(\"Please ensure 'BBC News Train.csv' is in the 'data' folder.\")\n    exit(1)\n\n# Basic info\nprint('Dataset Info:')\nprint(train_df.info())\nprint('\\nMissing Values:')\nprint(train_df.isnull().sum())\n\n# Category distribution\nprint('\\nCategory Distribution:')\ncategory_counts = train_df['Category'].value_counts()\nprint(category_counts)\nplt.figure(figsize=(8, 6))\nplt.bar(category_counts.index, category_counts.values)\nplt.title('Distribution of Article Categories')\nplt.xlabel('Category')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.savefig('category_distribution.png')\nplt.close()\n\n# Article length analysis\ntry:\n    train_df['text_length'] = train_df['Text'].apply(lambda x: len(word_tokenize(x)))\n    print('\\nText Length Statistics:')\n    print(train_df['text_length'].describe())\n    plt.figure(figsize=(8, 6))\n    plt.hist(train_df['text_length'], bins=50, edgecolor='black')\n    plt.title('Distribution of Article Text Lengths')\n    plt.xlabel('Number of Words')\n    plt.ylabel('Frequency')\n    plt.savefig('text_length_distribution.png')\n    plt.close()\nexcept LookupError as e:\n    print(f'Error in text length analysis (NLTK punkt missing): {e}')\n    print(\"Please ensure 'english.pickle' is in nltk_data/tokenizers/punkt/PY3/. Download from: https://github.com/nltk/nltk_data/raw/gh-pages/packages/tokenizers/punkt.zip\")\n    print(\"Verify folder structure with:\")\n    print(\"import os\")\n    print(\"print(os.listdir('nltk_data/tokenizers/punkt/PY3'))\")\n    exit(1)\n\n# Most common words\ntry:\n    all_text = ' '.join(train_df['Text'].values)\n    tokens = word_tokenize(all_text.lower())\n    word_counts = Counter(tokens)\n    common_words = word_counts.most_common(20)\n    words, counts = zip(*common_words)\n    plt.figure(figsize=(10, 6))\n    plt.barh(words, counts)\n    plt.title('Top 20 Most Common Words')\n    plt.xlabel('Frequency')\n    plt.ylabel('Word')\n    plt.savefig('common_words.png')\n    plt.close()\nexcept LookupError as e:\n    print(f'Error in common words analysis (NLTK punkt missing): {e}')\n    print(\"Please ensure 'english.pickle' is in nltk_data/tokenizers/punkt/PY3/. Download from: https://github.com/nltk/nltk_data/raw/gh-pages/packages/tokenizers/punkt.zip\")\n    print(\"Verify folder structure with:\")\n    print(\"import os\")\n    print(\"print(os.listdir('nltk_data/tokenizers/punkt/PY3'))\")\n    exit(1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1490 entries, 0 to 1489\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   ArticleId  1490 non-null   int64 \n 1   Text       1490 non-null   object\n 2   Category   1490 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 23.4+ KB\nNone\n\nMissing Values:\nArticleId    0\nText         0\nCategory     0\ndtype: int64\n\nCategory Distribution:\nCategory\nsport            346\nbusiness         336\npolitics         274\nentertainment    273\ntech             261\nName: count, dtype: int64\n\nText Length Statistics:\ncount    1490.000000\nmean      406.687248\nstd       221.932994\nmin        95.000000\n25%       266.000000\n50%       356.500000\n75%       494.000000\nmax      3496.000000\nName: text_length, dtype: float64\n"
        }
      ],
      "execution_count": 19
    },
    {
      "id": "96e9a523-e1c7-49be-9634-cfca2ecbabb1",
      "cell_type": "code",
      "source": "## 2. Supervised Learning\n# Preprocess text, convert to TF-IDF features, and train Logistic Regression and Naive Bayes classifiers.\n\nimport nltk\nimport os\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pickle\n\n# Add local nltk_data to NLTK path\nnltk.data.path.append(os.path.join(os.getcwd(), 'nltk_data'))\n\n# Text preprocessing\ntry:\n    stop_words = set(stopwords.words('english'))\nexcept LookupError:\n    print(\"Error: NLTK 'stopwords' not found. Download from: https://github.com/nltk/nltk_data/raw/gh-pages/packages/corpora/stopwords.zip and place in nltk_data/corpora/stopwords/\")\n    exit(1)\n\ntry:\n    lemmatizer = WordNetLemmatizer()\nexcept LookupError:\n    print(\"Error: NLTK 'wordnet' not found. Download from: https://github.com/nltk/nltk_data/raw/gh-pages/packages/corpora/wordnet.zip and place in nltk_data/corpora/wordnet/\")\n    exit(1)\n\ndef preprocess_text(text):\n    try:\n        tokens = word_tokenize(text.lower())\n        tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n        return ' '.join(tokens)\n    except LookupError as e:\n        print(f'Error in text preprocessing (NLTK punkt missing): {e}')\n        print(\"Please ensure 'english.pickle' is in nltk_data/tokenizers/punkt/PY3/\")\n        exit(1)\n\n# Apply preprocessing\ntry:\n    train_df['processed_text'] = train_df['Text'].apply(preprocess_text)\nexcept NameError:\n    print(\"Error: 'train_df' not defined. Please run the EDA section first to load 'BBC News Train.csv'.\")\n    exit(1)\n\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX = tfidf.fit_transform(train_df['processed_text'])\ny = train_df['Category']\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression\nlr_model = LogisticRegression(max_iter=1000, multi_class='multinomial')\nlr_model.fit(X_train, y_train)\nlr_pred = lr_model.predict(X_val)\nprint('Logistic Regression Results:')\nprint(f'Accuracy: {accuracy_score(y_val, lr_pred):.4f}')\nprint(classification_report(y_val, lr_pred))\n\n# Train Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(X_train, y_train)\nnb_pred = nb_model.predict(X_val)\nprint('\\nNaive Bayes Results:')\nprint(f'Accuracy: {accuracy_score(y_val, nb_pred):.4f}')\nprint(classification_report(y_val, nb_pred))\n\n# Save models and vectorizer\ntry:\n    with open('tfidf_vectorizer.pkl', 'wb') as f:\n        pickle.dump(tfidf, f)\n    with open('lr_model.pkl', 'wb') as f:\n        pickle.dump(lr_model, f)\n    with open('nb_model.pkl', 'wb') as f:\n        pickle.dump(nb_model, f)\n    print(\"Saved: tfidf_vectorizer.pkl, lr_model.pkl, nb_model.pkl\")\nexcept Exception as e:\n    print(f\"Error saving models: {e}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Logistic Regression Results:\nAccuracy: 0.9732\n               precision    recall  f1-score   support\n\n     business       0.97      0.97      0.97        75\nentertainment       0.98      1.00      0.99        46\n     politics       0.96      0.95      0.95        56\n        sport       0.97      1.00      0.98        63\n         tech       0.98      0.95      0.96        58\n\n     accuracy                           0.97       298\n    macro avg       0.97      0.97      0.97       298\n weighted avg       0.97      0.97      0.97       298\n\n\nNaive Bayes Results:\nAccuracy: 0.9765\n               precision    recall  f1-score   support\n\n     business       0.97      0.97      0.97        75\nentertainment       1.00      1.00      1.00        46\n     politics       0.95      0.95      0.95        56\n        sport       0.98      1.00      0.99        63\n         tech       0.98      0.97      0.97        58\n\n     accuracy                           0.98       298\n    macro avg       0.98      0.98      0.98       298\n weighted avg       0.98      0.98      0.98       298\n\nSaved: tfidf_vectorizer.pkl, lr_model.pkl, nb_model.pkl\n"
        }
      ],
      "execution_count": 20
    },
    {
      "id": "7370f68a-7269-4079-a409-e362833057a4",
      "cell_type": "code",
      "source": "## 3. Unsupervised Learning (Topic Modeling)\n# Apply NMF to discover latent topics in the articles.\n\nimport numpy as np\nfrom sklearn.decomposition import NMF\n\n# Assume X and tfidf from Supervised Learning\ntry:\n    # Apply NMF\n    n_topics = 5  # Matches number of categories\n    nmf = NMF(n_components=n_topics, random_state=42)\n    W = nmf.fit_transform(X)  # Document-topic matrix\n    H = nmf.components_      # Topic-term matrix\n\n    # Get top words per topic\n    feature_names = tfidf.get_feature_names_out()\n    for topic_idx, topic in enumerate(H):\n        top_words = [feature_names[i] for i in topic.argsort()[-10:]]\n        print(f'Topic {topic_idx + 1}: {\", \".join(top_words)}')\n\n    # Assign dominant topic to each article\n    train_df['dominant_topic'] = np.argmax(W, axis=1)\n    print('\\nArticles per Topic:')\n    print(train_df['dominant_topic'].value_counts())\n\n    # Save topic assignments\n    try:\n        train_df[['ArticleId', 'Category', 'dominant_topic']].to_csv('topic_assignments.csv', index=False)\n        print(\"Saved: topic_assignments.csv\")\n    except Exception as e:\n        print(f\"Error saving topic assignments: {e}\")\nexcept NameError:\n    print(\"Error: 'X', 'tfidf', or 'train_df' not defined. Please run the Supervised Learning section first.\")\n    exit(1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Topic 1: director, nomination, actress, festival, star, oscar, actor, best, award, film\nTopic 2: tax, mr blair, said, tory, brown, party, blair, election, labour, mr\nTopic 3: gadget, digital, user, said, service, music, technology, people, phone, mobile\nTopic 4: side, said, cup, ireland, wale, match, player, win, england, game\nTopic 5: economic, price, sale, bank, year, market, rate, economy, said, growth\n\nArticles per Topic:\ndominant_topic\n3    399\n4    340\n2    295\n1    266\n0    190\nName: count, dtype: int64\nSaved: topic_assignments.csv\n"
        }
      ],
      "execution_count": 21
    },
    {
      "id": "d78ace85-9250-4955-91f0-ad140b4f84e3",
      "cell_type": "code",
      "source": "## 4. Kaggle Submission\n# Generate predictions for the test set using the trained model.\n\nimport pandas as pd\nimport pickle\nimport os\n\n# Add local nltk_data to NLTK path\nnltk.data.path.append(os.path.join(os.getcwd(), 'nltk_data'))\n\n# Function to find datasets\ndef find_dataset(filename):\n    possible_paths = [\n        os.path.join('data', filename),\n        filename,\n        os.path.join('datasets', filename)\n    ]\n    for path in possible_paths:\n        if os.path.exists(path):\n            return path\n    raise FileNotFoundError(f\"Dataset '{filename}' not found in {os.getcwd()}. Checked paths: {possible_paths}. Please place the file in the 'data' folder.\")\n\n# Load test data\ntry:\n    test_dataset_path = find_dataset('BBC News Test.csv')\n    test_df = pd.read_csv(test_dataset_path)\nexcept FileNotFoundError as e:\n    print(e)\n    print(\"Please ensure 'BBC News Test.csv' is in the 'data' folder.\")\n    exit(1)\n\n# Preprocess test data (reuse preprocess_text from Supervised Learning)\ndef preprocess_text(text):\n    try:\n        from nltk.corpus import stopwords\n        from nltk.stem import WordNetLemmatizer\n        from nltk.tokenize import word_tokenize\n        stop_words = set(stopwords.words('english'))\n        lemmatizer = WordNetLemmatizer()\n        tokens = word_tokenize(text.lower())\n        tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n        return ' '.join(tokens)\n    except LookupError as e:\n        print(f'Error in text preprocessing: {e}')\n        print(\"Ensure 'punkt', 'stopwords', and 'wordnet' are in nltk_data/\")\n        exit(1)\n\ntest_df['processed_text'] = test_df['Text'].apply(preprocess_text)\n\n# Load vectorizer and model\ntry:\n    with open('tfidf_vectorizer.pkl', 'rb') as f:\n        tfidf = pickle.load(f)\n    with open('lr_model.pkl', 'rb') as f:\n        lr_model = pickle.load(f)\nexcept FileNotFoundError as e:\n    print(f'Error: Model or vectorizer file not found: {e}')\n    print(\"Please run the Supervised Learning section to generate 'tfidf_vectorizer.pkl' and 'lr_model.pkl'.\")\n    exit(1)\n\n# Transform test data\nX_test = tfidf.transform(test_df['processed_text'])\n\n# Predict\npredictions = lr_model.predict(X_test)\n\n# Create submission file\ntry:\n    submission_df = pd.DataFrame({'ArticleId': test_df['ArticleId'], 'Category': predictions})\n    submission_df.to_csv('submission.csv', index=False)\n    print('Submission file created: submission.csv')\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Submission file created: submission.csv\n"
        }
      ],
      "execution_count": 22
    },
    {
      "id": "638ca559-4a16-436e-831b-d1617373333b",
      "cell_type": "code",
      "source": "## 5. Comparison of Supervised and Unsupervised Learning\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n# Load topic assignments\ntry:\n    topic_df = pd.read_csv('topic_assignments.csv')\nexcept FileNotFoundError:\n    print(\"Error: 'topic_assignments.csv' not found. Please run Unsupervised Learning section.\")\n    exit(1)\n\n# Map NMF topics to categories (based on Section 3 output)\ntopic_to_category = {\n    0: 'entertainment',\n    1: 'politics',\n    2: 'tech',\n    3: 'sport',\n    4: 'business'\n}\n\n# Assign predicted categories from NMF\ntopic_df['nmf_predicted_category'] = topic_df['dominant_topic'].map(topic_to_category)\n\n# Calculate NMF accuracy\nnmf_accuracy = (topic_df['nmf_predicted_category'] == topic_df['Category']).mean()\nprint(f'NMF Topic Modeling Accuracy: {nmf_accuracy:.4f}')\n\n# Confusion matrix for NMF\nlabels = ['business', 'entertainment', 'politics', 'sport', 'tech']\ncm_nmf = confusion_matrix(topic_df['Category'], topic_df['nmf_predicted_category'], labels=labels)\n\n# Print confusion matrix with category labels as comments\nprint('\\nNMF Confusion Matrix:')\nfor i, row in enumerate(cm_nmf):\n    row_str = ' [' + ' '.join(f'{x:>3}' for x in row) + ']'\n    print(f'{row_str}  # {labels[i].capitalize()}')\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nplt.imshow(cm_nmf, interpolation='nearest', cmap='Blues')\nplt.title('NMF Confusion Matrix')\nplt.colorbar()\ntick_marks = np.arange(len(labels))\nplt.xticks(tick_marks, labels, rotation=45)\nplt.yticks(tick_marks, labels)\nfor i in range(len(labels)):\n    for j in range(len(labels)):\n        plt.text(j, i, cm_nmf[i, j], ha='center', va='center')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('nmf_confusion_matrix.png')\nplt.close()\n\n# Comparison analysis\nprint(\"\"\"\n### Comparison Analysis\n- **Supervised Learning (Logistic Regression, Naive Bayes)**:\n  - **Accuracy**: Logistic Regression (97.32%), Naive Bayes (97.65%) on validation set.\n  - **Strengths**: High accuracy, direct category prediction, robust to text variations.\n  - **Weaknesses**: Requires labeled data, less interpretable feature importance.\n- **Unsupervised Learning (NMF Topic Modeling)**:\n  - **Accuracy**: ~{:.4f} (based on topic-to-category mapping).\n  - **Strengths**: Discovers latent topics without labels, interpretable topic words (e.g., 'film' for entertainment).\n  - **Weaknesses**: Lower accuracy, topic-to-category mapping is subjective, uneven topic distribution.\n- **Key Differences**:\n  - Supervised models excel in classification tasks with labeled data.\n  - NMF is better for exploratory analysis, identifying themes without supervision.\n- **Conclusion**: Supervised learning outperforms NMF for classification due to direct label prediction, but NMF provides valuable insights into article themes.\n\"\"\".format(nmf_accuracy))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "NMF Topic Modeling Accuracy: 0.8906\n\nNMF Confusion Matrix:\n [312   0  11   3  10]  # Business\n [  7 187   7  29  43]  # Entertainment\n [ 17   0 245   8   4]  # Politics\n [  0   1   0 345   0]  # Sport\n [  4   2   3  14 238]  # Tech\n\n### Comparison Analysis\n- **Supervised Learning (Logistic Regression, Naive Bayes)**:\n  - **Accuracy**: Logistic Regression (97.32%), Naive Bayes (97.65%) on validation set.\n  - **Strengths**: High accuracy, direct category prediction, robust to text variations.\n  - **Weaknesses**: Requires labeled data, less interpretable feature importance.\n- **Unsupervised Learning (NMF Topic Modeling)**:\n  - **Accuracy**: ~0.8906 (based on topic-to-category mapping).\n  - **Strengths**: Discovers latent topics without labels, interpretable topic words (e.g., 'film' for entertainment).\n  - **Weaknesses**: Lower accuracy, topic-to-category mapping is subjective, uneven topic distribution.\n- **Key Differences**:\n  - Supervised models excel in classification tasks with labeled data.\n  - NMF is better for exploratory analysis, identifying themes without supervision.\n- **Conclusion**: Supervised learning outperforms NMF for classification due to direct label prediction, but NMF provides valuable insights into article themes.\n\n"
        }
      ],
      "execution_count": 23
    },
    {
      "id": "813dd9aa-b227-4b47-9aec-fdbfe7a603ec",
      "cell_type": "code",
      "source": "## 6. Local Evaluation\n# Compare submission.csv with BBC News Sample Solution.csv to estimate performance.\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, classification_report\nimport os\n\n# Function to find datasets\ndef find_dataset(filename):\n    possible_paths = [\n        os.path.join('data', filename),\n        filename,\n        os.path.join('datasets', filename)\n    ]\n    for path in possible_paths:\n        if os.path.exists(path):\n            return path\n    raise FileNotFoundError(f\"Dataset '{filename}' not found in {os.getcwd()}.\")\n\n# Load submission and sample solution\ntry:\n    submission_df = pd.read_csv('submission.csv')\n    sample_solution_path = find_dataset('BBC News Sample Solution.csv')\n    sample_solution_df = pd.read_csv(sample_solution_path)\nexcept FileNotFoundError as e:\n    print(f'Error: {e}')\n    print(\"Please ensure 'submission.csv' and 'BBC News Sample Solution.csv' are available.\")\n    exit(1)\n\n# Merge and compare predictions\nmerged_df = submission_df.merge(sample_solution_df, on='ArticleId', suffixes=('_pred', '_true'))\naccuracy = (merged_df['Category_pred'] == merged_df['Category_true']).mean()\nprint(f'Local Evaluation Accuracy: {accuracy:.4f}')\n\n# Detailed classification report\nprint('\\nClassification Report:')\nprint(classification_report(merged_df['Category_true'], merged_df['Category_pred']))\n\n# Save evaluation results\ntry:\n    merged_df.to_csv('submission_evaluation.csv', index=False)\n    print(\"Saved: submission_evaluation.csv\")\nexcept Exception as e:\n    print(f\"Error saving evaluation: {e}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Local Evaluation Accuracy: 0.1918\n\nClassification Report:\n               precision    recall  f1-score   support\n\n     business       0.20      0.24      0.22       147\nentertainment       0.21      0.16      0.18       147\n     politics       0.16      0.16      0.16       147\n        sport       0.20      0.23      0.22       147\n         tech       0.18      0.16      0.17       147\n\n     accuracy                           0.19       735\n    macro avg       0.19      0.19      0.19       735\n weighted avg       0.19      0.19      0.19       735\n\nSaved: submission_evaluation.csv\n"
        }
      ],
      "execution_count": 24
    },
    {
      "id": "bb41f2e3-0026-4061-a4d5-514ff4e6d5ff",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}